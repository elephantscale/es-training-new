{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'http://datakmeans.s3.amazonaws.com/uber-raw-data-apr14.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We are taking a portion of the data from the Uber data set\n",
    "uber_data = pd.read_csv('/path/to/csv/uber-raw-data-apr14.csv', header=0)\n",
    "print(uber_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uber_data[:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Converting the Date column into seperate values \n",
    "date_col = []\n",
    "for i in range(len(uber_data)):\n",
    "    #print (i)\n",
    "    for form in (\"%m-%d-%Y  %H:%M\", \"%m/%d/%Y  %H:%M:%S\"):\n",
    "        try:\n",
    "            #print (form)\n",
    "            date_col.append(datetime.datetime.strptime(uber_data['Date_Time'][i], form))\n",
    "        except ValueError:\n",
    "            pass\n",
    "            \n",
    "    \n",
    "#date_col = datetime.datetime.strptime(uber_data['Date_Time'], \"%b-%d-%Y  %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = []\n",
    "month = []\n",
    "day = []\n",
    "hours = []\n",
    "minu = []\n",
    "for i in range(len(date_col)):\n",
    "    year.append(date_col[i].year)\n",
    "    month.append(date_col[i].month)\n",
    "    day.append(date_col[i].day)\n",
    "    hours.append(date_col[i].hour)\n",
    "    minu.append(date_col[i].minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data1 = uber_data\n",
    "uber_data1['year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data1['month'] = month\n",
    "uber_data1['day'] = day\n",
    "uber_data1['hour'] = hours\n",
    "uber_data1['minute'] = minu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(uber_data['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#uber_final = uber_data1[['Lat','Lon','Base','year','month','day','hour','minute']]\n",
    "uber_loc = uber_data1[['Lat','Lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_loc[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_final = uber_loc.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import KMeans\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "# TODO: Edit the bucket and data_location\n",
    "bucket = \"sagemaker-sai1\"\n",
    "data_location = \"sagemaker-sai1\"\n",
    "\n",
    "\n",
    "data_location = 's3://{}/data/location'.format(bucket)\n",
    "output_location = 's3://{}/output/location'.format(bucket)\n",
    "\n",
    "print('training data will be uploaded to: {}'.format(data_location))\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))\n",
    "\n",
    "kmeans = KMeans(role=role,\n",
    "                train_instance_count=1,\n",
    "                train_instance_type='ml.p2.xlarge',\n",
    "                output_path=output_location,\n",
    "                k=5,\n",
    "                data_location=data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model using the Numpy array\n",
    "# hint - Use method record_set(your numpy array) in kmeans package\n",
    "%%time\n",
    "\n",
    "# TODO: Edit the argument to 'fit'\n",
    "kmeans.fit(kmeans.??(uber_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model we just trained behind a real-time hosted endpoint using kmeans.deploy()\n",
    "# Specify the initial_instance_count and instance_type as arguments in deploy()\n",
    "%%time\n",
    "\n",
    "kmeans_predictor = kmeans.deploy(initial_instance_count=1,\n",
    "                                 instance_type='ml.p2.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Validate the model for use, Take a small subset of the data and \n",
    "# see the results of the clustering using kmeans_predictor.predict(your_array[Specify a range])\n",
    "\n",
    "# TODO: Edit the predictor function to call\n",
    "test_result = kmeans_predictor.??(uber_final[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#result = kmeans_predictor.predict(s)\n",
    "clusters = [r.label['closest_cluster'].float32_tensor.values[0] for r in test_result]\n",
    "i = 0\n",
    " \n",
    "    \n",
    "for r in test_result:\n",
    "    out = {\n",
    "        \"Date\"     : uber_data1['Date_Time'].iloc[i],\n",
    "        \"Latitude\":uber_data1['Lat'].iloc[i],\n",
    "        \"Longitude\" : uber_data1['Lon'].iloc[i],  \n",
    "        \"closest_cluster\" :  r.label['closest_cluster'].float32_tensor.values[0],\n",
    "        \"Base Code\" : uber_data1['Base'].iloc[i],  \n",
    "    }    \n",
    "    print(out) \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "#So, Next we may use the clusters for finding,\n",
    " #1. Number of pickups in the year 2014 with closest cluster = 1 on month 4 and day 1?\n",
    " #2. How many pickups occurred in each cluster? \n",
    " #3. No of cabs booked in a particular clustering, day, month, hour."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
