<span dir="ltr"><span class="underline">Video Catalog</span></span>

# **<span dir="ltr">Machine Learning</span>**

##  <span dir="ltr">Video 4 Git Repo (Getting Started with Machine Learning)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Getting Started with Machine Learning: Cloning Git
Repository</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Cloning the Git repository with the data for the Machine
Learning course. How to set up the data for the course. Using Github
Desktop</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:05:40</span>

##  <span dir="ltr">V2-1-Lab-2a (Week 1 Brief Introduction to Pandas)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Brief Introduction to Pandas</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Briefly introducing Lab 2a</span>

<span dir="ltr">Open jupyter notebook, open pandas notebook, and go over
pandas notebook, have students do pandas lab</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Nothing of note</span>

**<span dir="ltr"><span class="underline">Related Lab:</span></span>**

<span dir="ltr">W1-2a-pandas.ipynb</span>

<span dir="ltr">Tested, no issues</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:01:52</span>

##  <span dir="ltr">V2-1-Pandas (Video 2: Introducing Datasets)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Video 2: Introducing Datasets</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Introduction to Pandas, creating Pandas series and
dataframe, conducting various operations with a dataframe, descriptive
statistics, advanced pandas operations like concatenating, using real
world datasets and data exploration.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Nothing of note</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:35:26</span>

##  <span dir="ltr">V2-2-Exploring-Pandas(Pandas and Files)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Pandas and Files</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Reading types of data files using pandas, saving data to
files, dealing with missing values, dealing with categorical variables.
Finish with a lab over NYCFlights13 dataset.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Nothing of note</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:09:10</span>

##  <span dir="ltr">V2-2-Lab-2b (Week 1 Lab 2b Exploring Pandas)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Exploring Pandas</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Going over pandas lab over the New York Dataset.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Nothing of note</span>

**<span dir="ltr"><span class="underline">Related Lab:</span></span>**

<span dir="ltr">W1-2b-exploring-pandas.ipynb</span>

<span dir="ltr">Tested, no issues</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:02:07</span>

##  <span dir="ltr">V2-3-Visualization (Python: Visualizations)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Visualizations</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Learn about Python Visualization, look over different
python packages(matplotlib, seaborn, ggpot, etc..), and do comparison
with statistical graphs .</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Nothing of note</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:18:51</span>

##  <span dir="ltr">V2-3-Lab-2c (Week 1 Lab 2c Intro Visualizations Lab)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Intro Visualizations Lab</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Going over the cars dataset using visualizations with
matplotlib and pandas. Brief look at the visualization lab. .</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Nothing of note</span>

**<span dir="ltr"><span class="underline">Related Lab:</span></span>**

<span dir="ltr">W1-2c-visualization-cars.ipynb</span>

<span dir="ltr">Tested, no issues</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:01:48</span>

##  <span dir="ltr">V2-4-Lab-2d (Week 1 Lab 2d: Visualization lab)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Week 1 Lab 2d: Visualization lab</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Going over to the visualization lab using matplotlib and
seaborn. Brief look over the lab.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Nothing of note</span>

**<span dir="ltr"><span class="underline">Related Lab:</span></span>**

<span dir="ltr">W1-2d-visualization-stats.ipynb</span>

<span dir="ltr">Tested, no issues.</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:01:30</span>

##  <span dir="ltr">V2-4-Visualization-Stats (Data Exploration)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Data Exploration</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Going further with data exploration. Using numerical
data analysis, covariance/correlation, and visualizing. Learn to do
explorative data analysis and some statistics for data science. Going
over data types</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Nothing of note</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:01:30</span>

## <span dir="ltr">V3-1-Lab-3a (Week 1 Lab 3a: Intro Scikit-learn)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Week 1 Lab 3a: Intro Scikit-learn</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Intro to SciKit-learn lab. Brief overview of lab.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Nothing of note</span>

**<span dir="ltr"><span class="underline">Related Lab:</span></span>**

<span dir="ltr">W1-3a-sklearn-intro.ipynb</span>

<span dir="ltr">Tested, updated code</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:01:30</span>

##  <span dir="ltr">V3-1-Sklearn (Video 3: Scikit-Learn Intro with Linear Regression)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Video 3: Scikit-Learn Intro with Linear
Regression</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Understand Scikit-learn in python, advantages and
disadvatanges, supervised machine learning, unsupervised machine
learning, and recommendations.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Nothing of note</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:29:55</span>

##  <span dir="ltr">V3-2-Lab-3b (Week 1 Lab 3b: Linear Regression Lab)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Week 1 Lab 3b: Linear Regression Lab: Linear Regression
Lab</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Quick overview of scikit-learn lab of bills and tips
lab, building a linear model with data. Using linear regression in
Scikit-learn.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Nothing of note</span>

**<span dir="ltr"><span class="underline">Related Lab:</span></span>**

<span dir="ltr">W1-3b-sklearn-lr.ipynb</span>

<span dir="ltr">Tested, no issues</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:01:38</span>

##  <span dir="ltr">V3-2-Linear Regression (Session: Linear Regression)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Session: Linear Regression</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Understanding linear regression with one variable,
introducing the model, explaining gradient descent solution, and
understanding linear regression with many variables.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Nothing of note</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:12:50</span>

##  <span dir="ltr">V3-3-LogisticRegression (Many Variables:Multiple Linear Regression)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Session: Linear Regression</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Understanding multiple linear regression. One variable,
gradient descent, many variables. Solutions advice by verifying the
dimensions, feature scaling, and choosing the learning rate.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Titled wrong. Should be multiple linear
regression.</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:07:16</span>

##  <span dir="ltr">W1\_V3-4-LogisticRegression (Logistic Regression)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Logistic Regression</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Introduction to logistic regression and its
applications. Includes an overview of logistic regression to
classification problems, the formula, multiple logistic regression, how
to prepare data for logistic regression</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">The content is good but the sound quality is poor
throughout most of the video.</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:10:54</span>

##  <span dir="ltr">W2\_V1a-Classification\_SVM (SVM Classification)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Video 1: Classification using SVM</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Overview of Support Vector Machines (SVM) in
Classification problems including theory, maximal margin classifiers,
hyper planes, soft margin classifiers. The different kinds of kernels
used with SVMs are also covered in this video as well as how to prepare
data for the SVM and what the potential drawbacks are.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No edits required</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:21:19</span>

##  <span dir="ltr">W2\_V1\_Lab\_1a\_1b(SVM College Admission Lab)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Session: SVM College Admission Lab</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Introduction to SVM lab which includes admissions data
and then creates a model to classify students as either admitted or not
admitted. Builds on the SVM lecture that precedes it.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No editing required.</span>

**<span dir="ltr"><span class="underline">Related Lab:</span></span>**

<span dir="ltr">W2-1a-svm-college.ipynb</span>

<span dir="ltr">Tested and fixed</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:02:38</span>

##  <span dir="ltr">W2\_V1b\_Classification\_NB (ROC and Naive Bayes)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Video 1: Classification: ROC and Naive Bayes</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Further coverage of classification models and evaluation
metrics with the confusion matrix, precision, recall and the ROC curve.
Then the video gives an overview of Naive Bayes as a useful
classification model including an overview of the math behind it.
Finally, an overview of how to prepare data for Naive Bayes and the
strengths and weaknesses of this class of models.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No edits required</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:27:41</span>

##  <span dir="ltr">W2\_V2b\_Lab\_2c(Naive Bayes Lab)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Naive Bayes Census Lab</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Introduction to Naive Bayes classifier lab. Using the
census dataset, the goal is to create a classifier to determine if
someone is making above or below 50,000 a year. This lab uses the
multinomial naive bayes from sklearn to create this classifier.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No editing required.</span>

**<span dir="ltr"><span class="underline">Related Lab:</span></span>**

<span dir="ltr">W2-2c-nbayes-income.ipynb</span>

<span dir="ltr">Tested, no issues</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:02:42</span>

##  <span dir="ltr">W2\_V2a\_Decision\_Trees (Decision Trees)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Week 2 Video 2: Decision Trees</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Introduction to the decision tree model and eventually
applying it to the college admissions dataset introduced previously.
Focus is on the algorithm and use cases applied to different examples.
More advanced concepts such as pruning are also covered. Finally the
strength and weaknesses of decision trees are covered as well as the
sklearn implementation</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No edits required</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:27:02</span>

##  <span dir="ltr">W2\_V2b\_Lab\_2a\_2b(Decision Tree Prosper Loan)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Decision Tree Prosper Loan Lab</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Introduction to Decision Tree lab. The goal is to use a
single decision tree from the sklearn implementation to determine the
loan status of individuals in the prosper loan dataset.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No editing required.</span>

**<span dir="ltr"><span class="underline">Related Lab:</span></span>**

<span dir="ltr">W2-2a-dec-tree-prosper.ipynb</span>

<span dir="ltr">Tested and fixed</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:02:58</span>

##  <span dir="ltr">W2\_V2b\_RandomForests (Random Forests)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Week 2 Video 2b: Random Forest</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">An overview of the problems with decision tree models,
the bias-variance tradeoff and how random forests are an evolution of
the decision and seek to mitigate some of these issues. It also
introduces the concept of model ensembling to create more powerful
models. Data bagging is presented as a method of preventing overfitting.
There is a discussion of the strengths and weaknesses of random forests
and introduces the sklearn implementation. The end of the video also
introduces the Random Forest lab which explains why there is not an
additional video for it.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No edits required</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:13:21</span>

##  <span dir="ltr">W2\_V3a\_Clustering (K-means Clustering)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Week 2 Video 3a: Unsupervised Learning: K-means
Clustering</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">An introduction to unsupervised learning approaches and
how they differ from supervised learning. The video also covers some use
cases for unsupervised learning and introduces clustering. This includes
an introduction to the concepts, examples and algorithms. Then the video
moves onto k-means clustering as an overview of the concept and the
algorithm. There is then a focus on how to evaluate k-means performance
such as WSSE and then the complexity of the algorithm and some
drawbacks. Finally the video discusses strengths and weaknesses of the
method and the implementation in python using sklearn.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No edits required  
</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:26:36</span>

##  <span dir="ltr">W2\_V3a\_Lab\_3a\_3b(Kmeans mtcars)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Week 2 Lab 3a: Kmeans mtcars example</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Introduction to Kmeans clustering lab. The goal of this
lab is to calculate Kmeans clusters on the mtcars dataset using the
sklearn implementation of this algorithm. The lab also implements
hyperparameter tuning to use the elbow method to determine the best
value for k by calculating wsse.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No editing required.</span>

**<span dir="ltr"><span class="underline">Related Lab:</span></span>**

<span dir="ltr">W2-3a-kmeans-mtcars.ipynb</span>

<span dir="ltr">Tested and fixed</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:03:52</span>

##  <span dir="ltr">W2\_V3b\_PCA (PCA)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Week 2 Video 3b: Unsupervised Learning: PCA</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">An introduction to dimensionality reduction as a method
of unsupervised learning. The first part of the video covers why
dimensionality reduction is effective. Specifically, the video covers
Principle Component Analysis (PCA) as well as why this is different than
clustering.This includes the concept as well as an example with
calculation behind the method. Additionally, the video covers
evaluation, visualizing of PCA and use cases and the sklearn
implementation.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No edits required</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:20:59</span>

##  <span dir="ltr">W2\_V3b\_PCA\_Lab\_3c ( PCA Lab)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

<span dir="ltr">Week 2 Lab 3c: PCA Wine Quality Example</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Introduction to PCA lab. The goal is to use PCA to
reduce the dimensionality on the wine quality dataset. This is done
using the sklearn implementation and using a biplot.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No editing required as long as code still exists.</span>

**<span dir="ltr"><span class="underline">Related Lab:</span></span>**

<span dir="ltr">w2-3c-pca-wine.ipynb</span>

<span dir="ltr">Tested, no issues</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:04:21</span>

##  <span dir="ltr">W3\_V1a\_Lab\_1a (Week 3 Lab 1a Deep Learning Playground)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">Deep Learning Playground</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Brief introduction to the Tensorflow Playground.</span>
<span dir="ltr"><span class="underline">https://playground.tensorflow.org/</span>.
How to manipulate the program to visualize deep learning training and
model manipulation.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Lab has been checked and is good to go.</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:03:20</span>

##  <span dir="ltr">W3\_V1b\_Lab\_1b (Week 3 Lab 1b Understanding Tensorflow Sessions)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">Understanding Tensorflow Sessions</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Introduction to Tensorflow Sessions lab. Lazy evaluation
and graph output. Eager evaluation in Tensorflow.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No editing needed as long as related lab still exists in
github</span>

**<span dir="ltr"><span class="underline">Related Lab:</span></span>**

<span dir="ltr">W3-1b-session.ipynb</span>

<span dir="ltr">Lab is fixed to tf version 2.0</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:01:24</span>

##  <span dir="ltr">W3\_V2a\_Lab\_2a\_2b (Week 3 Lab 2a: Tips and 2b: MNIST Linear)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">Linear Regression in Tensorflow</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Introduction to Tensorflow Regression labs: bill vs. tip
example and linear MNIST. Set up a class for tf linear regression and
plotting results. Use of tensorflow variables, gradient descent as
applied to low level API use of tensorflow.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No editing needed as long as related labs still exists
in github</span>

<span dir="ltr">Code must be updated to tf v2.0</span>

**<span dir="ltr"><span class="underline">Related Labs:</span></span>**

<span dir="ltr">w3-2a-tips.ipynb : Fixed to tf v2.0</span>

<span dir="ltr">w3-2b-mnist-linear.ipynb</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:02:22</span>

##  <span dir="ltr">W3\_V2b\_Lab\_2c\_2d (Week 3 Lab 2c: Estimator Cars and 2d: Keras Linear MNIST)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">Keras Estimator API in TensorFlow</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Introduction to Tensorflow Keras Estimator labs: cars
and linear MNIST. Building a linear regression estimator and run
predictions. Use of Keras API to build estimator. Simple model
construction for linear regression.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

**<span dir="ltr"><span class="underline">Related Labs:</span></span>**

<span dir="ltr">w3-2c-estimator-cars.ipynb</span>

<span dir="ltr">W3-2d-keras-linear-mnist.ipynb : Lab tested and ready to
go</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:02:15</span>

##  <span dir="ltr">W3\_V3a\_MLP (Week 3 video: Multi-Layer Perceptrons)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">Mult-Layer Perceptrons</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">An introduction to Multi-Layer Perceptrons including
Hidden Layers, optimizers, and activation functions. An overview on the
basics of deep learning optimizers including gradient descent, momentum,
Adam. Activation functions covered include sigmoid and tanh activation
functions, the vanish gradient concept, softmax.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No editing required</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:21:45</span>

##  <span dir="ltr">W3\_V3a\_Lab\_3a (Week 3 Lab 3a: DL playground with hidden layer)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">Deep Learning Playground with Hidden Layers</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Use of Tensorflow Playground to create a simple
Multi-Layer Perceptron (MLP).</span>
<span dir="ltr"><span class="underline">https://playground.tensorflow.org/</span>.
Adding hidden layers to the network in the program to see the effect
when changing the amount of neurons and applying to different standard
datasets</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

**<span dir="ltr"><span class="underline">Related Labs:</span></span>**

<span dir="ltr">W3-3a-dl-playground-hidden-layer.md : Checked and Good
to go.</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:01:51</span>

##  <span dir="ltr">W3\_V3a\_Lab\_3b\_3c (Week 3 Lab 3b: DNN Low Level Intro and Lab 3c: )</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">DNN Intro and DNN Intro using Keras</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Introduction to Lab 3b and Lab 3c. Creation of a DNN
using the low level tensorflow API to create an estimator. Creation of a
DNN using the keras implementation of DNN to streamline model
construction on the MNIST dataset.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

**<span dir="ltr"><span class="underline">Related Labs:</span></span>**

<span dir="ltr">W3-3b-dnn-intro-lowlevel.ipynb : Lab edited to tf
v2.0</span>

<span dir="ltr">W3-3c-dnn-intro-keras.ipynb</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:02:57</span>

##  <span dir="ltr">W3\_V3b\_Lab\_3d\_3e (Week 3 Lab 3d: DNN Iris Estimator and Lab 3e: DNN Iris using Keras )</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">DNN Iris Classifier Intro and DNN Iris Classifier Intro using Keras</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Introduction to Lab 3d and Lab 3e. Using a simple DNN to
create a classifier on the Iris dataset with tensorflow. The first lab
is using the estimator API and the second is using the Keras API</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Code must be updated to tf v2.0</span>

**<span dir="ltr"><span class="underline">Related Labs:</span></span>**

<span dir="ltr">w3-3d-dnn-estimator-irisipynb</span>

<span dir="ltr">W3-3e-dnn-keras-iris.ipynb</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:04:32</span>

## <span dir="ltr">W4\_V01\_CNN (CNN)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">Introducing CNNs</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">An introduction to image recognition and why CNNs help
mitigate some of the problems with feed forward networks on large
amounts of image data. Next is an overview of the history of CNNs and
the important concepts such as convolutions, pooling, ReLU activation.
Then there is a full example of the computation of convolution on an
example. Finally, a walk through of the full architecture of a CNN and
major issues.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No editing required</span>

**<span dir="ltr"><span class="underline">Related Labs:</span></span>**

<span dir="ltr">None</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:33:30</span>

## <span dir="ltr">W4\_V02\_CNN (CNN in Tensorflow)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">CNN in Tensorflow</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">The video is primarily about implementing CNNs in
Tensorflow and includes information such as what the input tensor shapes
should be and how to create the convolutional layer and the pooling
layer. The convolutions intro lab is shown as a code example. Next the
CNN MNIST lab is introduced and the code is shown which has
implementations in both base tf and keras. Finally, the CNN fashion lab
is introduced and the code is shown.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">All code shown in both the slides and the labs is from
tensorflow v1 and must be changed to the new version.</span>

**<span dir="ltr"><span class="underline">Related Labs:</span></span>**

<span dir="ltr">6.1-convolutions-intro.ipynb</span>

<span dir="ltr">6.2-cnn-mnist.ipynb</span>

<span dir="ltr">6.3-cnn-fashion.ipynb</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:20:45</span>

## <span dir="ltr">W4\_V03\_Tensorboard (Tensorboard)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">Tensorboard</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">The video introduces the tensorboard tool from
tensorflow and shows an example with MNIST in both jupyter notebook and
colab. The focus is on just running a tensorflow model and then
visualizing the results using tensorboard.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

**<span dir="ltr"><span class="underline">Related Labs:</span></span>**

<span dir="ltr">w4-4-tensorboard.ipynb</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:10:33</span>

##  <span dir="ltr">W5\_V1\_Transferlearning (Transfer Learning)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">Transfer Learning</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Understanding transfer learning, pre-trained models, and
customizing pretrained models. Look at some examples of transfer
learning models. Applying the model to your data. Comparison of
different transfer learning architectures. Inception is best on
performance, accuracy, and size of network.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Slide title is misspelled, “Transfer Leraning.</span>

**<span dir="ltr"><span class="underline">Related Labs:</span></span>**

<span dir="ltr">None</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:15:51</span>

##  <span dir="ltr">W5\_V2\_RNN (Tensorflow RNN)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">Introducing RNN’s</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Understanding the meaning of Recurrence and RNN’s, why
recurrence creates memory and state in NN, and learn how to implement
RNN in Tensorflow. Different types of RNN’s. Disadvantages of RNN’s.
Show lab doing a manual RNN, using a static RNN, packing sequences,
dynamic RNN, and multi-layer RNN.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">No notes</span>

**<span dir="ltr"><span class="underline">Related Labs:</span></span>**

<span dir="ltr">W5-2a-rnn-intro.ipynb</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:29:30</span>

##  <span dir="ltr">W5\_V3\_LSTM (Long Short Term Memory (LSTM) Neural Networks)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">Long Short Term Memory (LSTM) Neural Neworks</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Learn about Long Short Term Memory(LSTM) Neural networks
and understand how to use them. One of the issues with RNN are long
training times. Components of LSTM, architecture, testing LSTM models.
Use LSTM model on MNIST dataset. Show lstm with stocks data. LSTM and
NLP. LSTM using word2vec using a txt data set.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">LSTM-stocks notebook had issues with loading stocks data
during video.</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:34:50</span>

**<span dir="ltr"><span class="underline">Related Labs:</span></span>**

<span dir="ltr">8.2-lstm-intro.ipynb</span>

<span dir="ltr">8.3-lstm-stocks.ipynb</span>

<span dir="ltr">8.4-word2vec.ipynb</span>

##  <span dir="ltr">W6\_V1\_Distributed (Week 6 Video: Scaling Machine Learning )</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">Scaling Machine Learning</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Overview of scaling ML including distributed TensorFlow,
Container Cluster Orchestration, Big Data Ecosystem, Cloud Platforms.
Tensorflow is optimized for use with GPUs and can be parallelized and
scaled for distributed training. Model serving cluster is useful in
scaling across multiple nodes. There is also an example using
distributed tensorflow that is presented. Container clusters such as
Kubernetes can be useful for scaling. Spark is another framework that
allows for scalability in machine learning. Finally this video covers
the cloud platforms such as AWS(Amazon) and GCP(Google) which both have
tools for machine learning on their platform. The Pancake stack as a
solution for deep learning on Big Data is also introduced.</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

**<span dir="ltr"><span class="underline">Related Labs:</span></span>**

<span dir="ltr">9.1-distributed.ipynb</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:31:30</span>

##  <span dir="ltr">W6\_V2\_FeatureEng (Week 6 Video: Feature Engineering)</span>

<span dir="ltr"><span class="underline">Link</span></span>

**<span dir="ltr"><span class="underline">Title:</span></span>**

## <span dir="ltr">Feature Engineering</span>

**<span dir="ltr"><span class="underline">Description:</span></span>**

<span dir="ltr">Overview of Feature Engineering and how to derive
features from raw data. This is done by mathematical transformation or
mapping to an output numerical feature that we can use more effectively
in our models. This video also contains an introduction to Kaggle and
the Titanic dataset. Transforming data columns into new features can
also lend a lot more power to a model. Feature Engineering is often done
using domain knowledge, understanding of data and experience. The end
introduces a lab listed below that uses the feature tools package and
nyc taxi data</span>

**<span dir="ltr"><span class="underline">Edit Notes :</span></span>**

<span dir="ltr">Make sure that lab still exists</span>

**<span dir="ltr"><span class="underline">Related Labs:</span></span>**

<span dir="ltr">w6-2-featuretools-nyc.ipynb</span>

<span dir="ltr">w6-2-featuretools-uk.ipynb</span>

**<span dir="ltr"><span class="underline">Length :</span></span>**

<span dir="ltr">00:25:19</span>
